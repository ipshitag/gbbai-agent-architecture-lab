{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbbai-agent-architecture-lab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r\"C:\\Users\\pablosal\\Desktop\\gbbai-agent-architecture-lab\"  # change your directory here\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Semantic Kernel Components\n",
    "\n",
    "Before diving into the implementation, let's understand the key components of Semantic Kernel.\n",
    "\n",
    "#### The Kernel\n",
    "\n",
    "The Kernel is the central orchestrator in Semantic Kernel. It manages:\n",
    "\n",
    "- **Connecting to AI Models**: Interfaces with various AI models via connectors.\n",
    "- **Registering and Invoking Plugins**: Manages the lifecycle and execution of plugins.\n",
    "- **Managing Memory and Context**: Maintains state and context across interactions.\n",
    "- **Interacting with the Planner**: Coordinates with the Planner to achieve specified goals.\n",
    "\n",
    "#### Connectors\n",
    "\n",
    "Connectors allow the Kernel to interface with various AI models and services. They define how the Kernel communicates with these models, whether they're:\n",
    "\n",
    "- **OpenAI Models**: Such as GPT-3.5, GPT-4.\n",
    "- **Azure OpenAI Services**: Leveraging Microsoft's cloud-based AI capabilities.\n",
    "- **Local Models**: Using libraries like Hugging Face Transformers.\n",
    "\n",
    "#### Plugins\n",
    "\n",
    "Plugins are modular units that extend the Kernel's functionality. They consist of:\n",
    "\n",
    "- **Prompt Functions**: Use natural language prompts to interact with AI models.\n",
    "- **Native Functions**: Written in Python, performing deterministic tasks or interfacing with external services.\n",
    "\n",
    "Plugins act as building blocks for complex workflows.\n",
    "\n",
    "#### The Planner\n",
    "\n",
    "The Planner uses AI to dynamically create a sequence of actions (a plan) to achieve a specified goal. It considers:\n",
    "\n",
    "- **Available Plugins and Their Functions**: Understands the capabilities of each plugin.\n",
    "- **Function Descriptions**: Uses metadata to understand what each function does.\n",
    "- **Combining Functions**: Determines how functions can be combined to fulfill the goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Smart Entity and Intent Recognition\n",
    "\n",
    " This guide illustrates a robust system with two key skills: **Intent Classification** and **Named Entity Recognition (NER)**. The architecture involves:\n",
    "\n",
    "### Key Skills\n",
    "\n",
    "1. **Intent Classification**: Determines the purpose of the user’s query, leveraging LLMs.\n",
    "2. **Entity Recognition**: Extracts entities like names, dates, or medical terms, using advanced Named Entity Recognition (NER) capabilities also laveraging LLMs.\n",
    "\n",
    "By leveraging Semantic Kernel's capabilities, we can create a robust system that avoids single points of failure by running in parallel and utilizing multiple skills. Let's dive in!\n",
    "\n",
    "### Implementation\n",
    "\n",
    "We will:\n",
    "\n",
    "1. **Define Plugins**: Create plugins for the Medical Researcher, Clinical Evaluator, and Medical Editor.\n",
    "2. **Configure the Kernel**: Set up the Kernel with the necessary connectors and plugins.\n",
    "3. **Develop the Planner**: Implement the Planner to dynamically orchestrate the workflow.\n",
    "4. **Execute the Plan**: Run the system to produce high-quality medical documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using the following semantic_kernel library version: 1.17.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install semantic-kernel --upgrade\n",
    "import semantic_kernel as sk\n",
    "print(f\"We are using the following semantic_kernel library version: {sk.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Plugins\n",
    "\n",
    "We have defined the plugin for MedicalAgents located in the specified directory  `C:\\Users\\pablosal\\Desktop\\gbbai-agent-architecture-lab\\src\\plugins\\plugins_store`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure The Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Azure OpenAI service connector to the kernel\n",
    "import os\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_ID = os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID_MINI\")\n",
    "\n",
    "service_id = \"openai-chat\"\n",
    "# Add Azure OpenAI chat completion\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=service_id,\n",
    "    deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT_ID,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered services: {'openai-chat': AzureChatCompletion(ai_model_id='gpt-4o-mini', service_id='openai-chat', client=<openai.lib.azure.AsyncAzureOpenAI object at 0x0000018BBF179E10>, ai_model_type=<OpenAIModelTypes.CHAT: 'chat'>, prompt_tokens=0, completion_tokens=0, total_tokens=0)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Registered services:\", kernel.services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-19 08:08:48 - semantic_kernel.functions.kernel_plugin:332 - WARNING] Failed to create function from directory: C:\\Users\\pablosal\\Desktop\\gbbai-agent-architecture-lab\\src\\plugins\\plugins_store\\medResearch\n",
      "[2024-12-19 08:08:48 - semantic_kernel.functions.kernel_plugin:332 - WARNING] Failed to create function from directory: C:\\Users\\pablosal\\Desktop\\gbbai-agent-architecture-lab\\src\\plugins\\plugins_store\\nlpToSqlPlugin\n",
      "[2024-12-19 08:08:48 - semantic_kernel.functions.kernel_plugin:332 - WARNING] Failed to create function from directory: C:\\Users\\pablosal\\Desktop\\gbbai-agent-architecture-lab\\src\\plugins\\plugins_store\\QueryDb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available functions in intentPlugin plugin:\n",
      "Loaded plugin functions: dict_keys(['intentPlugin', 'nerPlugin'])\n",
      "name='intentPlugin' plugin_name='plugins_store' description='Classify a sports-related user query into one of the predefined intent categories (e.g., summarize, historical, scores, etc.)' parameters=[KernelParameterMetadata(name='input', description='The user’s sports-related query or statement to be classified', default_value='', type_='', is_required=True, type_object=None, schema_data={'type': 'object', 'description': 'The user’s sports-related query or statement to be classified'}, include_in_function_choices=True)] is_prompt=True is_asynchronous=True return_parameter=KernelParameterMetadata(name='return', description='The completion result', default_value=None, type_='FunctionResult', is_required=True, type_object=None, schema_data=None, include_in_function_choices=True) additional_properties=None\n"
     ]
    }
   ],
   "source": [
    "# Define the parent directory and plugin name\n",
    "parent_directory = os.path.abspath(os.path.join(\"src\", \"plugins\"))\n",
    "plugin_name = \"plugins_store\"\n",
    "\n",
    "# Add the plugin to the kernel\n",
    "plugin = kernel.add_plugin(parent_directory=parent_directory, plugin_name=plugin_name)\n",
    "\n",
    "print(\"Available functions in intentPlugin plugin:\")\n",
    "\n",
    "print(\"Loaded plugin functions:\", plugin.functions.keys())\n",
    "\n",
    "print(plugin.functions['intentPlugin'].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: {'input': 'I just need a high-level recap of the Warriors’ playoff performance.'}\n",
      "Result: ```json\n",
      "{ \"intent\": \"summarize\" }\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "\n",
    "arguments = KernelArguments(input=\"I just need a high-level recap of the Warriors’ playoff performance.\")\n",
    "print(\"Arguments:\", arguments)\n",
    "\n",
    "result = await kernel.invoke(plugin.functions['intentPlugin'], arguments, service_id=\"openai-chat\")\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: {'input': 'I just need a high-level recap of the Warriors’ playoff performance.'}\n",
      "Result: ```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    { \"text\": \"Warriors\", \"category\": \"Organization\" },\n",
      "    { \"text\": \"playoff\", \"category\": \"Event\" }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "\n",
    "arguments = KernelArguments(input=\"I just need a high-level recap of the Warriors’ playoff performance.\")\n",
    "print(\"Arguments:\", arguments)\n",
    "\n",
    "result = await kernel.invoke(plugin.functions['nerPlugin'], arguments, service_id=\"openai-chat\")\n",
    "print(\"Result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Develop the Planer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "\n",
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto() # the automatic planning loop https://learn.microsoft.com/en-us/semantic-kernel/concepts/planning?pivots=programming-language-python#the-automatic-planning-loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execute the Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response: ```json\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"text\": \"Warriors\",\n",
      "      \"category\": \"Organization\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"playoff\",\n",
      "      \"category\": \"Event\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent\": \"summarize\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "import logging\n",
    "from semantic_kernel.utils.logging import setup_logging\n",
    "\n",
    "# Create a history of the conversation\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "# Add system message to the chat history to define the system's role\n",
    "chat_history.add_system_message(\n",
    "    \"You are an AI-powered assistant specializing in Named Entity Recognition (NER) and Intent Classification. \"\n",
    "    \"Your goal is to analyze user input, extract named entities, classify the user's intent, and return results in a structured JSON format. \"\n",
    "    \"The JSON should include the following fields: \"\n",
    "    \"1. 'entities': A list of named entities found in the user input, each with 'text' and 'category' fields. \"\n",
    "    \"2. 'intent': The classified intent of the user input. \"\n",
    "\n",
    "    \"The intent can only be one of the following categories: \"\n",
    "    \"- summarize \"\n",
    "    \"- historical \"\n",
    "    \"- statistics \"\n",
    "    \"- schedule \"\n",
    "    \"- roster \"\n",
    "    \"- standings \"\n",
    "    \"- support \"\n",
    "    \"- catchMeUp \"\n",
    "    \"- scores \"\n",
    "    \"- None \"\n",
    "\n",
    "    \"The named entities should be classified into one of the following categories: \"\n",
    "    \"1. **Person**: Names of individuals. \"\n",
    "    \"2. **PersonType**: Roles or job titles (e.g., 'coach', 'player'). \"\n",
    "    \"3. **Location**: Geographic or geopolitical entities (e.g., 'Paris', 'Dodger Stadium'). \"\n",
    "    \"4. **Organization**: Teams, companies, or institutions (e.g., 'ESPN', 'New York Yankees'). \"\n",
    "    \"5. **Event**: Sporting events, historical events, or cultural holidays (e.g., 'Super Bowl 2023'). \"\n",
    "    \"6. **Product**: Physical or conceptual items (e.g., 'iPhone 15'). \"\n",
    "    \"7. **Skill**: Capabilities or expertise (e.g., '3-point shooting', 'machine learning'). \"\n",
    "    \"8. **Address**: Mailing or physical addresses (e.g., '1600 Pennsylvania Avenue'). \"\n",
    "    \"9. **PhoneNumber**: Telephone numbers in any supported format (e.g., '+1-202-555-0191'). \"\n",
    "    \"10. **Email**: Email addresses (e.g., 'contact@example.com'). \"\n",
    "    \"11. **URL**: Links to websites (e.g., 'https://example.com'). \"\n",
    "    \"12. **IP**: Network IP addresses (e.g., '192.168.0.1'). \"\n",
    "    \"13. **DateTime**: Dates, times, or time-related phrases (e.g., 'next Monday', 'July 4, 2025'). \"\n",
    "    \"14. **Quantity**: Numerical values, measurements, or percentages (e.g., '50%', '6 feet tall'). \"\n",
    "\n",
    "    \"Here are some examples of the expected JSON format: \"\n",
    "\n",
    "    \"Example 1: \"\n",
    "    \"{ \"\n",
    "    \"'entities': [\"\n",
    "    \"{ 'text': 'LeBron James', 'category': 'Person' }, \"\n",
    "    \"{ 'text': '50', 'category': 'Quantity' }, \"\n",
    "    \"{ 'text': 'yesterday', 'category': 'DateTime' }, \"\n",
    "    \"{ 'text': 'Warriors', 'category': 'Organization' }\"\n",
    "    \"], \"\n",
    "    \"'intent': 'scores' \"\n",
    "    \"}, \"\n",
    "\n",
    "    \"Example 2: \"\n",
    "    \"{ \"\n",
    "    \"'entities': [\"\n",
    "    \"{ 'text': 'Paris', 'category': 'Location' }, \"\n",
    "    \"{ 'text': 'Eiffel Tower', 'category': 'Location' }, \"\n",
    "    \"{ 'text': 'next week', 'category': 'DateTime' }\"\n",
    "    \"], \"\n",
    "    \"'intent': 'schedule' \"\n",
    "    \"}, \"\n",
    "\n",
    "    \"Example 3: \"\n",
    "    \"{ \"\n",
    "    \"'entities': [\"\n",
    "    \"{ 'text': 'Apple', 'category': 'Organization' }, \"\n",
    "    \"{ 'text': 'iPhone 15', 'category': 'Product' }, \"\n",
    "    \"{ 'text': 'release date', 'category': 'DateTime' }\"\n",
    "    \"], \"\n",
    "    \"'intent': 'None' \"\n",
    "    \"}\"\n",
    ")\n",
    "\n",
    "# Add user message to the chat history\n",
    "user_input = \"I just need a high-level recap of the Warriors’ playoff performance.\"\n",
    "chat_history.add_user_message(user_input)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s - %(name)s:%(lineno)d - %(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "setup_logging()\n",
    "logging.getLogger(\"kernel\").setLevel(logging.INFO)\n",
    "\n",
    "# Get the response from the AI\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    "    kernel=kernel,\n",
    "    arguments=KernelArguments(input=\"The impact of AI on medical diagnostics\"),\n",
    "))[0]\n",
    "\n",
    "# Print the result\n",
    "print(\"AI Response:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-framework-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
